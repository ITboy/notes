# 高并发系统限制
## 网络带宽 ##
从用户请求到应用服务器之间，第一个环节就是网络运营商，当你在向运营商申请带宽的时候申请一定数量的带宽，这个带宽分为上行和下行，用户的请求数据包对服务器而言是下行带宽，而对于用户的响应数据则是上行带宽。一般对于web服务器，响应包总是大于请求包，所以对服务器而言，申请带宽时上行带宽要大于下行带宽。

## 网卡速率 ##
网络带宽申请再大，如果大于网卡速率也是浪费，因为网卡只能处理速率固定的数据。现在网卡一般分为百兆或千兆网卡，对于服务器，就用千兆网卡吧。

## 应用服务器处理能力 ##
一般而言网络带宽和网卡速率很难成为瓶颈，因为理论上申请的网络带宽可以无限大（仅受限于接入运营商的运营商设备的处理能力，大于千兆网卡速率），所以如果只有一台load balance作为应用系统入口的情况下，仍然可以处理1000Mbps的数据，假设用户请求数据包平均大小为1k，那么每秒可以处理125k个请求（12.5万tps），这个值已经能满足大多数的高并发了，所以现在瓶颈是应用服务器处理能力。

### 负载均衡器 ###
暂时认为load balance不是瓶颈，等将来对负载均衡有更多了解再补充

### 应用程序 ###
用户请求经过网络，经过负载均衡器抵达应用程序服务器后，最先要做的是把应用程序处理，数据库服务器和文件服务器做分离。
1. 文件服务器必须做分离
其实就是我们常说的动静分离，因为这部分是不需要任何处理的最简单的请求响应方式，但是文件包含各种图片，html，css，图片文件大、小文件也多，一方面考虑把带宽分解到多台机器上，另一方面，这种请求主要的瓶颈在于磁盘IO，对他单独做优化的时候更有针对性。
2. 数据库服务器分离
数据库的请求要比普通的文件访问要复杂，要经过数据库引擎的处理。常常成为系统的瓶颈，所以一定要做的是首先分离，让他独享专门的磁盘IO，CPU，内存等资源。
3. 应用程序
应用程序要负责业务处理，更多需要CPU和内存资源，并负责协调多个IO。

总之，将这三者分离是系统优化的第一要紧的，分离之后，他们各有自己的特点，再逐个进行优化。

### 文件服务器 ###
#### 缓存 ####
任何优化第一要想到是缓存，文件服务器的缓存包括多处：
1. 浏览器缓存
2. CDN
3. 反向代理缓存

#### 分布式 ####
当带宽或磁盘IO不够时，可以将他们分布在多个机器上，比如图片放在专门的服务器，他的分布式非常简单。

#### 压缩与合并 ####
不论是图片还是css，js等都可以压缩，以及合并到同一个文件

### 应用程序服务器 ###
